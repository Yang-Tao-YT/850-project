{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/yangtao/Documents/GitHub/850-project'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Function.Function import *\n",
    "from os.path import abspath , join\n",
    "from sklearn.preprocessing import normalize ,LabelEncoder\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "current_folder =abspath('');current_folder\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_calibrate = 0.8 #  days for train\n",
    "N_validation = 1 - N_calibrate # days for test\n",
    "# data = pd.read_csv('Data/finalproject_training.csv')\n",
    "data = pd.read_csv('Data/finalproject_training_xy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the xs that was cleaned for useless price data and non number data and NONE data(first check)\n",
    "data = data.loc[:,data.columns[12:]]\n",
    "data = data.loc[:,(np.array(data.dtypes == 'int64') ) | \\\n",
    "                               (np.array(data.dtypes == 'float64') )].dropna()\n",
    "# separate X and Y\n",
    "X_data = data.iloc[:,:-1]\n",
    "Y_data = data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Bullish', 'Neutral', 'Bearish', 'Bullish8WeekMovAvg',\n",
       "       'SP500WeeklyHigh', 'SP500WeeklyLow', 'SP500WeeklyClose', 'fyearq',\n",
       "       'fqtr', 'actq', 'atq', 'ceqq', 'cheq', 'chq', 'ciq', 'csh12q',\n",
       "       'cshfd12', 'cshfdq', 'cshopq', 'cshprq', 'dd1q', 'dlttq', 'dpq',\n",
       "       'epsf12', 'epsfxq', 'epspxq', 'epsx12', 'esopctq', 'gdwlq', 'ibadjq',\n",
       "       'ibcomq', 'ibmiiq', 'ibq', 'intanq', 'invtq', 'lctq', 'lltq', 'loq',\n",
       "       'lseq', 'ltq', 'niq', 'nopiq', 'oiadpq', 'oibdpq', 'piq', 'rdipq',\n",
       "       'rectq', 'req', 'revtq', 'tfvaq', 'tfvceq', 'tfvlq', 'txdbclq', 'txtq',\n",
       "       'xaccq', 'xintq', 'xoprq', 'xrdq', 'fincfy', 'intpny', 'ivncfy',\n",
       "       'oancfy', 'txpdy', 'dvpspq', 'dvpsxq', 'mkvaltq', 'ggroup', 'gind',\n",
       "       'gsector', 'gsubind', 'sic', 'm_ret_next'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#normalization or standardlization(i did normalization here)\n",
    "X_data = pd.DataFrame(normalize(data, axis=0) , columns = data.columns , index = data.index)\n",
    "\n",
    "# calibrate and standlization\n",
    "\n",
    "X_data ,Y_data = get_data(X_data,Y_data,N_calibrate , N_validation)\n",
    "X_data['calibrate']['processed'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264     -0.058568\n",
       "265     -0.082949\n",
       "266     -0.065327\n",
       "267     -0.026882\n",
       "268     -0.002762\n",
       "           ...   \n",
       "82064   -0.063069\n",
       "82065    0.110340\n",
       "82066    0.045625\n",
       "82067    0.140466\n",
       "82068    0.009434\n",
       "Name: m_ret_next, Length: 2220, dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_data['calibrate']['processed']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder or PCA ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lets do Autoencoder with nerual network first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension_of_input  = len(X_data['calibrate']['processed'].T) # number of stock\n",
    "autoencoder = inital_model(dimension_of_input) # inital_model 具体initial的model在function文件里\n",
    "# train model\n",
    "# we use net difference to train model\n",
    "Autoencoder_data = np.array(X_data['calibrate']['processed']) \n",
    "# we use pre-trained model to save time\n",
    "# autoencoder.fit(Autoencoder_data, Autoencoder_data, shuffle=False, epochs=500, batch_size = 10 , verbose = 0)\n",
    "\n",
    "# autoencoder.save(join(current_folder,'Models/com_autoencoder_{}.h5'.format(1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict and see what the factors is most relevent and explain most variance\n",
    "# dimension reduction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>communal</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.512206</td>\n",
       "      <td>fyearq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.688031</td>\n",
       "      <td>txdbclq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.028400</td>\n",
       "      <td>SP500WeeklyHigh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.030410</td>\n",
       "      <td>SP500WeeklyClose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.064121</td>\n",
       "      <td>SP500WeeklyLow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>18.411558</td>\n",
       "      <td>xintq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>20.577379</td>\n",
       "      <td>intpny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>25.312495</td>\n",
       "      <td>epsf12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>25.343811</td>\n",
       "      <td>epsx12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>29.843581</td>\n",
       "      <td>m_ret_next</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     communal             index\n",
       "0    0.512206            fyearq\n",
       "1    1.688031           txdbclq\n",
       "2    3.028400   SP500WeeklyHigh\n",
       "3    3.030410  SP500WeeklyClose\n",
       "4    3.064121    SP500WeeklyLow\n",
       "..        ...               ...\n",
       "67  18.411558             xintq\n",
       "68  20.577379            intpny\n",
       "69  25.312495            epsf12\n",
       "70  25.343811            epsx12\n",
       "71  29.843581        m_ret_next\n",
       "\n",
       "[72 rows x 2 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = join(current_folder,'Models/com_autoencoder_{}.h5'.format(1))\n",
    "autoencoder = load_model(path)\n",
    "predict = autoencoder.predict(Autoencoder_data) \n",
    "# use different error measure to decide which factors explain most variance\n",
    "\n",
    "# we need to figure out what is the best error measure,?\n",
    "\n",
    "# sum absolute relative error\n",
    "communal_information = np.sum(np.absolute((Autoencoder_data - predict)),axis = 0) \n",
    "# ranking\n",
    "ranking = np.array(communal_information).argsort()\n",
    "ranks = pd.DataFrame({'communal' : communal_information[ranking] ,'index' : X_data['calibrate']['processed'].columns[ranking] })\n",
    "ranks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lower the communal_information,higer explaination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### you can do prediction by using autoencoder directly. i can write it down if we decide to do it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets do PCA\n",
    "### from here you either use pca classifier or linear regression for prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = X_data['calibrate']['processed']\n",
    "# .loc[:,X_data['calibrate']['processed'].columns[ranking[:50]]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using pca in LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X = data\n",
    "y = np.array(Y_data['calibrate']['processed'])\n",
    "pca = PCA(n_components=5) #initial model\n",
    "X_pca = pca.fit_transform(X) # pca decomposition\n",
    "\n",
    "model_pca = LinearRegression()# initial predicition model\n",
    "model_pca.fit(X_pca,y) # fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010555496388554847"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(model_pca.predict(X_pca),y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test =  np.array(X_data['validation']['processed']) \n",
    "X_test_pca = pca.fit_transform(X_test)\n",
    "y_test = np.array(Y_data['validation']['processed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008637792249545856"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# out of sample, the score looks good to me\n",
    "mean_squared_error(model.predict(X_test_pca),y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save space for autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegression()# initial predicition model\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1270357874896637e-32"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(model.predict(X),y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0623258936254214e-31"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(model.predict(X_test),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.05856833, -0.08294931, -0.06532663, ...,  0.045625  ,\n",
       "        0.14046623,  0.00943396])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
