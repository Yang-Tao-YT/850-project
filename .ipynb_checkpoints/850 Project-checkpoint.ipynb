{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/yangtao/Documents/GitHub/850-project'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Function.Function import *\n",
    "from os.path import abspath , join\n",
    "from sklearn.preprocessing import normalize ,LabelEncoder\n",
    "\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "current_folder =abspath('');current_folder\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_calibrate = 0.8 #  days for train\n",
    "N_validation = 1 - N_calibrate # days for test\n",
    "data = pd.read_csv('Data/finalproject_training.csv')\n",
    "\n",
    "# the xs that was cleaned for useless price data and non number data and NONE data(first check)\n",
    "data = data.loc[:,data.columns[12:]]\n",
    "data = data.loc[:,(np.array(data.dtypes == 'int64') ) | \\\n",
    "                               (np.array(data.dtypes == 'float64') )].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bullish</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Bearish</th>\n",
       "      <th>Bullish8WeekMovAvg</th>\n",
       "      <th>SP500WeeklyHigh</th>\n",
       "      <th>SP500WeeklyLow</th>\n",
       "      <th>SP500WeeklyClose</th>\n",
       "      <th>fyearq</th>\n",
       "      <th>fqtr</th>\n",
       "      <th>actq</th>\n",
       "      <th>...</th>\n",
       "      <th>oancfy</th>\n",
       "      <th>txpdy</th>\n",
       "      <th>dvpspq</th>\n",
       "      <th>dvpsxq</th>\n",
       "      <th>mkvaltq</th>\n",
       "      <th>ggroup</th>\n",
       "      <th>gind</th>\n",
       "      <th>gsector</th>\n",
       "      <th>gsubind</th>\n",
       "      <th>sic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.294243</td>\n",
       "      <td>0.409382</td>\n",
       "      <td>0.296375</td>\n",
       "      <td>0.325835</td>\n",
       "      <td>2193.42</td>\n",
       "      <td>2168.50</td>\n",
       "      <td>2175.44</td>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>3530.000</td>\n",
       "      <td>...</td>\n",
       "      <td>559.000</td>\n",
       "      <td>54.000</td>\n",
       "      <td>0.1150</td>\n",
       "      <td>0.1150</td>\n",
       "      <td>15587.6400</td>\n",
       "      <td>3520</td>\n",
       "      <td>352030</td>\n",
       "      <td>35</td>\n",
       "      <td>35203010</td>\n",
       "      <td>3826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.294243</td>\n",
       "      <td>0.409382</td>\n",
       "      <td>0.296375</td>\n",
       "      <td>0.325835</td>\n",
       "      <td>2193.42</td>\n",
       "      <td>2168.50</td>\n",
       "      <td>2175.44</td>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>93761.000</td>\n",
       "      <td>...</td>\n",
       "      <td>49698.000</td>\n",
       "      <td>8990.000</td>\n",
       "      <td>0.5700</td>\n",
       "      <td>0.5700</td>\n",
       "      <td>515586.5740</td>\n",
       "      <td>4520</td>\n",
       "      <td>452020</td>\n",
       "      <td>45</td>\n",
       "      <td>45202030</td>\n",
       "      <td>3663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.294243</td>\n",
       "      <td>0.409382</td>\n",
       "      <td>0.296375</td>\n",
       "      <td>0.325835</td>\n",
       "      <td>2193.42</td>\n",
       "      <td>2168.50</td>\n",
       "      <td>2175.44</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>263.164</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.853</td>\n",
       "      <td>2.578</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1175.5510</td>\n",
       "      <td>3520</td>\n",
       "      <td>352010</td>\n",
       "      <td>35</td>\n",
       "      <td>35201010</td>\n",
       "      <td>2836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.294243</td>\n",
       "      <td>0.409382</td>\n",
       "      <td>0.296375</td>\n",
       "      <td>0.325835</td>\n",
       "      <td>2193.42</td>\n",
       "      <td>2168.50</td>\n",
       "      <td>2175.44</td>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>7399.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1669.000</td>\n",
       "      <td>40.000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>28416.7033</td>\n",
       "      <td>4530</td>\n",
       "      <td>453010</td>\n",
       "      <td>45</td>\n",
       "      <td>45301010</td>\n",
       "      <td>3559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>0.294243</td>\n",
       "      <td>0.409382</td>\n",
       "      <td>0.296375</td>\n",
       "      <td>0.325835</td>\n",
       "      <td>2193.42</td>\n",
       "      <td>2168.50</td>\n",
       "      <td>2175.44</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>140.414</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>1.964</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>40.9306</td>\n",
       "      <td>4520</td>\n",
       "      <td>452010</td>\n",
       "      <td>45</td>\n",
       "      <td>45201020</td>\n",
       "      <td>3663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105196</th>\n",
       "      <td>0.261307</td>\n",
       "      <td>0.316583</td>\n",
       "      <td>0.422111</td>\n",
       "      <td>0.296648</td>\n",
       "      <td>2939.08</td>\n",
       "      <td>2834.97</td>\n",
       "      <td>2887.94</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>1295.382</td>\n",
       "      <td>...</td>\n",
       "      <td>352.175</td>\n",
       "      <td>62.214</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>24795.4997</td>\n",
       "      <td>4510</td>\n",
       "      <td>451020</td>\n",
       "      <td>45</td>\n",
       "      <td>45102030</td>\n",
       "      <td>7370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105226</th>\n",
       "      <td>0.261307</td>\n",
       "      <td>0.316583</td>\n",
       "      <td>0.422111</td>\n",
       "      <td>0.296648</td>\n",
       "      <td>2939.08</td>\n",
       "      <td>2834.97</td>\n",
       "      <td>2887.94</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>8477.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1547.000</td>\n",
       "      <td>377.000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>14027.2500</td>\n",
       "      <td>4520</td>\n",
       "      <td>452020</td>\n",
       "      <td>45</td>\n",
       "      <td>45202030</td>\n",
       "      <td>3572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105283</th>\n",
       "      <td>0.261307</td>\n",
       "      <td>0.316583</td>\n",
       "      <td>0.422111</td>\n",
       "      <td>0.296648</td>\n",
       "      <td>2939.08</td>\n",
       "      <td>2834.97</td>\n",
       "      <td>2887.94</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>1298.109</td>\n",
       "      <td>...</td>\n",
       "      <td>219.202</td>\n",
       "      <td>54.757</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>6973.8245</td>\n",
       "      <td>2010</td>\n",
       "      <td>201060</td>\n",
       "      <td>20</td>\n",
       "      <td>20106020</td>\n",
       "      <td>3620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105298</th>\n",
       "      <td>0.261307</td>\n",
       "      <td>0.316583</td>\n",
       "      <td>0.422111</td>\n",
       "      <td>0.296648</td>\n",
       "      <td>2939.08</td>\n",
       "      <td>2834.97</td>\n",
       "      <td>2887.94</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>3589.568</td>\n",
       "      <td>...</td>\n",
       "      <td>298.216</td>\n",
       "      <td>1.661</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>29600.2784</td>\n",
       "      <td>4530</td>\n",
       "      <td>453010</td>\n",
       "      <td>45</td>\n",
       "      <td>45301020</td>\n",
       "      <td>3674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105305</th>\n",
       "      <td>0.261307</td>\n",
       "      <td>0.316583</td>\n",
       "      <td>0.422111</td>\n",
       "      <td>0.296648</td>\n",
       "      <td>2939.08</td>\n",
       "      <td>2834.97</td>\n",
       "      <td>2887.94</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>307.834</td>\n",
       "      <td>...</td>\n",
       "      <td>68.893</td>\n",
       "      <td>6.457</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>1015.8694</td>\n",
       "      <td>4510</td>\n",
       "      <td>451030</td>\n",
       "      <td>45</td>\n",
       "      <td>45103020</td>\n",
       "      <td>3674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2845 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Bullish   Neutral   Bearish  Bullish8WeekMovAvg  SP500WeeklyHigh  \\\n",
       "0       0.294243  0.409382  0.296375            0.325835          2193.42   \n",
       "8       0.294243  0.409382  0.296375            0.325835          2193.42   \n",
       "34      0.294243  0.409382  0.296375            0.325835          2193.42   \n",
       "127     0.294243  0.409382  0.296375            0.325835          2193.42   \n",
       "259     0.294243  0.409382  0.296375            0.325835          2193.42   \n",
       "...          ...       ...       ...                 ...              ...   \n",
       "105196  0.261307  0.316583  0.422111            0.296648          2939.08   \n",
       "105226  0.261307  0.316583  0.422111            0.296648          2939.08   \n",
       "105283  0.261307  0.316583  0.422111            0.296648          2939.08   \n",
       "105298  0.261307  0.316583  0.422111            0.296648          2939.08   \n",
       "105305  0.261307  0.316583  0.422111            0.296648          2939.08   \n",
       "\n",
       "        SP500WeeklyLow  SP500WeeklyClose  fyearq  fqtr       actq  ...  \\\n",
       "0              2168.50           2175.44    2016     3   3530.000  ...   \n",
       "8              2168.50           2175.44    2016     3  93761.000  ...   \n",
       "34             2168.50           2175.44    2016     2    263.164  ...   \n",
       "127            2168.50           2175.44    2016     3   7399.000  ...   \n",
       "259            2168.50           2175.44    2016     4    140.414  ...   \n",
       "...                ...               ...     ...   ...        ...  ...   \n",
       "105196         2834.97           2887.94    2019     2   1295.382  ...   \n",
       "105226         2834.97           2887.94    2019     4   8477.000  ...   \n",
       "105283         2834.97           2887.94    2019     3   1298.109  ...   \n",
       "105298         2834.97           2887.94    2019     1   3589.568  ...   \n",
       "105305         2834.97           2887.94    2019     2    307.834  ...   \n",
       "\n",
       "           oancfy     txpdy  dvpspq  dvpsxq      mkvaltq  ggroup    gind  \\\n",
       "0         559.000    54.000  0.1150  0.1150   15587.6400    3520  352030   \n",
       "8       49698.000  8990.000  0.5700  0.5700  515586.5740    4520  452020   \n",
       "34         -2.853     2.578  0.0000  0.0000    1175.5510    3520  352010   \n",
       "127      1669.000    40.000  0.1000  0.1000   28416.7033    4530  453010   \n",
       "259        -0.126     1.964  0.0000  0.0000      40.9306    4520  452010   \n",
       "...           ...       ...     ...     ...          ...     ...     ...   \n",
       "105196    352.175    62.214  0.0000  0.0000   24795.4997    4510  451020   \n",
       "105226   1547.000   377.000  0.5000  0.5000   14027.2500    4520  452020   \n",
       "105283    219.202    54.757  0.1625  0.1625    6973.8245    2010  201060   \n",
       "105298    298.216     1.661  0.3700  0.3700   29600.2784    4530  453010   \n",
       "105305     68.893     6.457  0.2000  0.2000    1015.8694    4510  451030   \n",
       "\n",
       "        gsector   gsubind   sic  \n",
       "0            35  35203010  3826  \n",
       "8            45  45202030  3663  \n",
       "34           35  35201010  2836  \n",
       "127          45  45301010  3559  \n",
       "259          45  45201020  3663  \n",
       "...         ...       ...   ...  \n",
       "105196       45  45102030  7370  \n",
       "105226       45  45202030  3572  \n",
       "105283       20  20106020  3620  \n",
       "105298       45  45301020  3674  \n",
       "105305       45  45103020  3674  \n",
       "\n",
       "[2845 rows x 71 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalization or standardlization(i did normalization here)\n",
    "data = pd.DataFrame(normalize(data, axis=0) , columns = data.columns , index = data.index)\n",
    "# calibrate and standlization\n",
    "X_data ,Y_data =get_data(data,N_calibrate , N_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Bullish', 'Neutral', 'Bearish', 'Bullish8WeekMovAvg',\n",
       "       'SP500WeeklyHigh', 'SP500WeeklyLow', 'SP500WeeklyClose', 'fyearq',\n",
       "       'fqtr', 'actq', 'ceqq', 'cheq', 'chq', 'ciq', 'csh12q', 'cshfd12',\n",
       "       'cshfdq', 'cshopq', 'cshprq', 'dd1q', 'dlttq', 'dpq', 'epsf12',\n",
       "       'epsfxq', 'epspxq', 'epsx12', 'esopctq', 'gdwlq', 'ibadjq', 'ibcomq',\n",
       "       'ibmiiq', 'ibq', 'intanq', 'invtq', 'lctq', 'lltq', 'loq', 'lseq',\n",
       "       'ltq', 'niq', 'nopiq', 'oiadpq', 'oibdpq', 'piq', 'rdipq', 'rectq',\n",
       "       'req', 'revtq', 'tfvaq', 'tfvceq', 'tfvlq', 'txdbclq', 'txtq', 'xaccq',\n",
       "       'xintq', 'xoprq', 'xrdq', 'fincfy', 'intpny', 'ivncfy', 'oancfy',\n",
       "       'txpdy', 'dvpspq', 'dvpsxq', 'mkvaltq', 'ggroup', 'gind', 'gsector',\n",
       "       'gsubind', 'sic'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data['calibrate']['processed'].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder or PCA ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lets do Autoencoder with nerual network first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa159057cd0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dimension_of_input  = len(X_data['calibrate']['processed'].T) # number of stock\n",
    "autoencoder = inital_model(dimension_of_input)\n",
    "# train model\n",
    "# we use net difference to train model\n",
    "data = np.array(X_data['calibrate']['processed']) \n",
    "autoencoder.fit(data, data, shuffle=False, epochs=500, batch_size = 10 , verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save(join(current_folder,'Models/com_autoencoder_{}.h5'.format(1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict and see what the factors is most relevent and explain most variance\n",
    "# dimension reduction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>communal</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.018323</td>\n",
       "      <td>fyearq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.927162</td>\n",
       "      <td>txdbclq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.920242</td>\n",
       "      <td>SP500WeeklyLow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.961752</td>\n",
       "      <td>SP500WeeklyClose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.230478</td>\n",
       "      <td>SP500WeeklyHigh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>19.160861</td>\n",
       "      <td>gdwlq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>20.581846</td>\n",
       "      <td>xintq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>22.069884</td>\n",
       "      <td>intpny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>24.697313</td>\n",
       "      <td>epsf12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>24.715637</td>\n",
       "      <td>epsx12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     communal             index\n",
       "0    0.018323            fyearq\n",
       "1    1.927162           txdbclq\n",
       "2    2.920242    SP500WeeklyLow\n",
       "3    2.961752  SP500WeeklyClose\n",
       "4    3.230478   SP500WeeklyHigh\n",
       "..        ...               ...\n",
       "65  19.160861             gdwlq\n",
       "66  20.581846             xintq\n",
       "67  22.069884            intpny\n",
       "68  24.697313            epsf12\n",
       "69  24.715637            epsx12\n",
       "\n",
       "[70 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = join(current_folder,'Models/com_autoencoder_{}.h5'.format(1))\n",
    "autoencoder = load_model(path)\n",
    "predict = autoencoder.predict(data) \n",
    "# use different error measure to decide which factors explain most variance\n",
    "\n",
    "# we need to figure out what is the best error measure,?\n",
    "\n",
    "# sum absolute relative error\n",
    "communal_information = np.sum(np.absolute((data - predict)),axis = 0) \n",
    "# ranking\n",
    "ranking = np.array(communal_information).argsort()\n",
    "ranks = pd.DataFrame({'communal' : communal_information[ranking] ,'index' : X_data['calibrate']['processed'].columns[ranking] })\n",
    "ranks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lower the communal_information,higer explaination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# you can do prediction by using autoencoder directly. i can write it down if we decide to do it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets do \n",
    "### from here you either use pca classifier or linear regression for prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pca classifier\n",
    "X = data\n",
    "y = np.array(Y_data['calibrate']['processed'])\n",
    "\n",
    "pca = PCA(2) #initial model\n",
    "\n",
    "X_reduced = pca.fit_transform(X) # pca decomposition\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier() # initial predicition model\n",
    "lab_enc = LabelEncoder()\n",
    "y = lab_enc.fit_transform(y) # transfer data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reduced, y) # splite test and train\n",
    "\n",
    "\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8681898066783831"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the score looks good to me\n",
    "rf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using pca in LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "X = data\n",
    "y = np.array(Y_data['calibrate']['processed'])\n",
    "pca = PCA(n_components=8) #initial model\n",
    "X_pca = pca.fit_transform(X) # pca decomposition\n",
    "\n",
    "model = LinearRegression()# initial predicition model\n",
    "model.fit(X_pca,y) # fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test =  np.array(X_data['validation']['processed']) \n",
    "X_test_pca = pca.fit_transform(X)\n",
    "y_test = np.array(Y_data['validation']['processed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.946570994225944"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# out of sample, the score looks good to me\n",
    "model.score(X_test_pca,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save for autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
